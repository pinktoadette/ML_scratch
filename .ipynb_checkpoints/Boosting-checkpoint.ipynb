{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "\n",
    "Types of boosting:\n",
    "- Ada boost: voting based where more weight on misclassified samples and lessweight on correct samples.\n",
    "- Gradient boost: integrates loss function, adds weak learners to minimize the loss function\n",
    "- XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost\n",
    "\n",
    "- create weights\n",
    "- calc epsilon\n",
    "- update weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a default weight, where all 1/n is equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weights(n):\n",
    "    return np.ones(n)*(1/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then resample the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(X, y, weights):\n",
    "    idx = np.random.choice(range(len(y)), size = len(y), p = weights)\n",
    "    return X[idx, :], y[idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the epsilon by giving actual/predicted labels and the weights.\n",
    "\n",
    "calculate the alpha, where alpha is dependent on the value of epsilon, of 0.5*(1-e)/e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon(y, y_pred, weights):\n",
    "    return weights[y != y_pred].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(epsilon):\n",
    "    return np.log((1-epsilon)/epsilon)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update the weights based on the alpha and actual vs predicted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights, alpha, y, y_pred):\n",
    "    def target_update(y):\n",
    "        target = y.copy()\n",
    "        target[target==0] = -1\n",
    "        return target\n",
    "    y = target_update(y)\n",
    "    pred = target_update(y_pred)\n",
    "    weights = weights*np.e**(-alpha*y*pred)\n",
    "    weights /= sum(weights)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_boost(X, y, n):\n",
    "    est = {}\n",
    "    for i in range(n_estimators):\n",
    "        boost_X, boost_y = resample(X, y, weights)\n",
    "\n",
    "        mod =  DecisionTreeClassifier(criterion = 'entropy', max_depth= 1)\n",
    "        mod.fit(bs_X, bs_y)\n",
    "\n",
    "        preds = mod.predict(X)\n",
    "\n",
    "        epsilon = epsilon(y, preds, weights)\n",
    "        alpha = alpha(epsilon)\n",
    "        \n",
    "        est[i] = (mod, alpha)\n",
    "        weights = update_weights(weights, alpha, y, preds)\n",
    "\n",
    "    return est_dict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
